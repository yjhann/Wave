import os
import json
import glob
from datetime import datetime
import traceback
from typing import List, Dict, Any

from vlm_qwen import load_qwen_vl, process_image_with_vlm
from vlm_prompt.extract_sources import get_scene_to_sound_prompt
from utils import find_image_files, ensure_dir


def find_images_in_data_folder(data_dir: str = "data") -> List[str]:
    """data í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì°¾ì•„ ë°˜í™˜"""
    image_files = find_image_files(data_dir)
    
    if not image_files:
        print(f"Data í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
    
    return image_files


def process_single_image(model, processor, image_path: str, output_dir: str, prompt: str, example_images: List) -> Dict[str, Any]:
    """ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ sound source JSON ìƒì„±"""
    print(f"\nì²˜ë¦¬ ì¤‘: {os.path.basename(image_path)}")
    
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    
    try:
        print("JSON ìƒì„± ì¤‘...")
        
        # VLMì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì²˜ë¦¬
        parsed = process_image_with_vlm(model, processor, image_path, prompt, example_images)
        
        result = {
            "image_path": image_path,
            "filename": base_name,
            "success": parsed['success'],
            "timestamp": datetime.now().isoformat()
        }
        
        if parsed['success']:
            json_data = parsed['json_data']
            
            # JSON êµ¬ì¡° ê²€ì¦
            validation_issues = validate_json_structure(json_data)
            total_variants = count_total_variants(json_data)
            
            result.update({
                "json_data": json_data,
                "total_variants": total_variants,
                "validation_issues": validation_issues,
                "meets_minimum_variants": total_variants >= 5,
                "sound_sources_count": len(json_data.get('sound_sources', [])),
                "scene_description": json_data.get('scene_description', 'N/A'),
                "mood_description": json_data.get('mood_description', 'N/A')
            })
            
            # ì´ë¯¸ì§€ë³„ í´ë” ìƒì„±
            image_output_dir = os.path.join(output_dir, base_name)
            os.makedirs(image_output_dir, exist_ok=True)
            
            # JSON íŒŒì¼ ì €ì¥
            json_filename = f"{base_name}_sound_source.json"
            json_path = os.path.join(image_output_dir, json_filename)
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=2, ensure_ascii=False)
            
            result["output_json_path"] = json_path
            
            print(f"âœ… ì„±ê³µ! Variants: {total_variants}/5")
            if total_variants < 5:
                print(f"âš ï¸ ìµœì†Œ ìš”êµ¬ì‚¬í•­ ë¯¸ë‹¬ (5ê°œ ë¯¸ë§Œ)")
            if validation_issues:
                print(f"âš ï¸ êµ¬ì¡° ë¬¸ì œ: {len(validation_issues)}ê°œ")
                
        else:
            result.update({
                "error": parsed['error'],
                "raw_response": parsed['raw_response']
            })
            print(f"âŒ ì‹¤íŒ¨: {parsed['error']}")
            
    except Exception as e:
        result.update({
            "success": False,
            "error": f"Processing error: {str(e)}",
            "traceback": traceback.format_exc()
        })
        print(f"ğŸ’¥ ì˜¤ë¥˜: {str(e)}")
    
    return result


def count_total_variants(json_data: Dict[str, Any]) -> int:
    """JSON ë°ì´í„°ì—ì„œ ì´ variants ìˆ˜ ê³„ì‚°"""
    if not isinstance(json_data, dict):
        return 0
    total_variants = 0
    for source in json_data.get('sound_sources', []):
        total_variants += len(source.get('variants', []))
    return total_variants


def validate_json_structure(json_data: Dict[str, Any]) -> List[str]:
    """JSON êµ¬ì¡° ê²€ì¦"""
    required_fields = ['scene_description', 'mood_description', 'sound_sources']
    issues = []
    
    for field in required_fields:
        if field not in json_data:
            issues.append(f"Missing field: {field}")
    
    if 'sound_sources' in json_data:
        sources = json_data['sound_sources']
        if not isinstance(sources, list):
            issues.append("sound_sources should be a list")
        else:
            for i, source in enumerate(sources):
                source_required = ['name', 'material', 'variants']
                for field in source_required:
                    if field not in source:
                        issues.append(f"sound_sources[{i}] missing field: {field}")
                
                if 'variants' in source:
                    for j, variant in enumerate(source['variants']):
                        variant_required = ['play_method', 'timbre', 'mapping_to_music_instrument']
                        for field in variant_required:
                            if field not in variant:
                                issues.append(f"sound_sources[{i}].variants[{j}] missing field: {field}")
    
    return issues


def batch_process_images(data_dir: str = "data", output_dir: str = "sound_sources") -> Dict[str, Any]:
    """data í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ ì²˜ë¦¬"""
    print("ğŸš€ ë°°ì¹˜ Sound Source ìƒì„± ì‹œì‘")
    print("=" * 80)

    ensure_dir(output_dir)
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    # VLM ëª¨ë¸ ë¡œë“œ
    print("VLM ëª¨ë¸ ë¡œë”© ì¤‘...")
    model, processor = load_qwen_vl()
    print(f"âœ… VLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! Device: {model.device}")
    
    # í”„ë¡¬í”„íŠ¸ ë° ì˜ˆì‹œ ë°ì´í„° ë¡œë“œ
    prompt, example_images = get_scene_to_sound_prompt()
    print(f"âœ… í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ! ì˜ˆì‹œ ì´ë¯¸ì§€: {len(example_images)}ê°œ")
  
    # data í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_files = find_images_in_data_folder(data_dir)
    
    if not image_files:
        print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        return {"error": "No images found"}
    
    print(f"ğŸ“¸ ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬")
    print("ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡:")
    for img_file in image_files:
        print(f"  - {os.path.basename(img_file)}")
    
    # ê²°ê³¼ ì €ì¥ìš©
    all_results = []
    successful_results = []
    failed_results = []
    insufficient_variants = []
    
    # ê° ì´ë¯¸ì§€ ì²˜ë¦¬
    print("\n" + "=" * 80)
    print("ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 80)
    
    for i, image_path in enumerate(image_files, 1):
        print(f"\n[{i}/{len(image_files)}]", end="")
        
        result = process_single_image(model, processor, image_path, output_dir, prompt, example_images)
        all_results.append(result)
        
        if result['success']:
            successful_results.append(result)
            if not result['meets_minimum_variants']:
                insufficient_variants.append(result)
        else:
            failed_results.append(result)
    
    # ì¢…í•© ê²°ê³¼ ì €ì¥
    summary = {
        "processing_info": {
            "timestamp": datetime.now().isoformat(),
            "total_images": len(image_files),
            "successful": len(successful_results),
            "failed": len(failed_results),
            "insufficient_variants": len(insufficient_variants)
        },
        "results": all_results
    }
    
    summary_path = os.path.join(output_dir, "processing_summary.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    # ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“Š ìµœì¢… ì²˜ë¦¬ ê²°ê³¼")
    print("=" * 80)
    print(f"ğŸ“¸ ì´ ì´ë¯¸ì§€ ìˆ˜: {len(image_files)}")
    print(f"âœ… ì„±ê³µ: {len(successful_results)}")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_results)}")
    print(f"âš ï¸ Variants ë¶€ì¡± (5ê°œ ë¯¸ë§Œ): {len(insufficient_variants)}")
    print(f"ğŸ“ ìš”ì•½ íŒŒì¼: {summary_path}")
    
    if insufficient_variants:
        print("\nğŸ” Variants ë¶€ì¡± íŒŒì¼ë“¤:")
        for result in insufficient_variants:
            print(f"  - {result['filename']}: {result['total_variants']}ê°œ variants")
    
    if failed_results:
        print("\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
        for result in failed_results:
            print(f"  - {result['filename']}: {result.get('error', 'Unknown error')}")
    
    # ì„±ê³µë¥  ê³„ì‚°
    success_rate = (len(successful_results) / len(image_files)) * 100
    minimum_variants_rate = ((len(successful_results) - len(insufficient_variants)) / len(image_files)) * 100
    
    print(f"\nğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
    print(f"ğŸ“ˆ ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë¥ : {minimum_variants_rate:.1f}%")
    
    return {
        "summary": summary,
        "successful_results": successful_results,
        "failed_results": failed_results,
        "insufficient_variants": insufficient_variants
    }


def process_single_image_with_vlm(image_path: str, output_dir: str) -> Dict[str, Any]:
    """ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ VLMìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê³ ìˆ˜ì¤€ í•¨ìˆ˜"""
    try:
        # VLM ëª¨ë¸ ë¡œë“œ
        print("VLM ëª¨ë¸ ë¡œë”© ì¤‘...")
        model, processor = load_qwen_vl()
        print(f"âœ… VLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! Device: {model.device}")
        
        # í”„ë¡¬í”„íŠ¸ ë° ì˜ˆì‹œ ë°ì´í„° ë¡œë“œ
        prompt, example_images = get_scene_to_sound_prompt()
        print(f"âœ… í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ! ì˜ˆì‹œ ì´ë¯¸ì§€: {len(example_images)}ê°œ")
        
        # ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
        result = process_single_image(model, processor, image_path, output_dir, prompt, example_images)
        return result
        
    except Exception as e:
        print(f"âŒ ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ìƒì„¸ ì˜¤ë¥˜:")
        print(traceback.format_exc())
        return {
            "success": False,
            "error": f"Processing error: {str(e)}",
            "traceback": traceback.format_exc()
        }


def run_batch_processing():
    """ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰"""
    try:
        results = batch_process_images()
        return results
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ìƒì„¸ ì˜¤ë¥˜:")
        print(traceback.format_exc())
        return None


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--single", type=str, default=None, help="ë‹¨ì¼ ì´ë¯¸ì§€ ê²½ë¡œ (ì˜ˆ: data/101.jpg)")
    parser.add_argument("--out", type=str, default="sound_sources", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--data", type=str, default="data", help="ì…ë ¥ ë°ì´í„° ë””ë ‰í† ë¦¬")
    args = parser.parse_args()

    print("ğŸš€ Sound Source ìƒì„±ê¸°")
    print(f"ARGS: single={args.single}, out={args.out}, data={args.data}")

    if args.single:
        print("ëª¨ë“œ: ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬")
        ensure_dir(args.out)
        
        res = process_single_image_with_vlm(args.single, args.out)
        if res.get("success"):
            print("\nğŸ‰ ë‹¨ì¼ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"JSON: {res.get('output_json_path')}")
        else:
            print("\nğŸ’¥ ë‹¨ì¼ ì²˜ë¦¬ ì‹¤íŒ¨!")
    else:
        print("ëª¨ë“œ: ë°°ì¹˜ ì²˜ë¦¬")
        # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
        results = run_batch_processing()
        if results:
            print("\nğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
            print("ìƒì„±ëœ íŒŒì¼ë“¤ì„ 'sound_sources' ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        else:
            print("\nğŸ’¥ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨!")